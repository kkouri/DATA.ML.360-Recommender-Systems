{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Project Work Part 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a)\n",
    "Downloading data and displaying some of it"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T16:11:00.836476Z",
     "start_time": "2024-11-07T16:11:00.139366Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import polars as pl\n",
    "\n",
    "# read data\n",
    "links_df = pl.read_csv(\"../data/links.csv\", schema={\"movieId\": pl.Int32, \"imdb\": pl.Int32, \"tmdbId\": pl.Int32})\n",
    "movies_df = (\n",
    "    pl.read_csv(\"../data/movies.csv\", schema={\"movieId\": pl.Int32, \"title\": pl.String, \"genres\": pl.String})\n",
    "    .with_row_index()\n",
    "    .with_columns(\n",
    "        pl.col(\"index\")\n",
    "        .cast(pl.Int32)\n",
    "    )\n",
    ")\n",
    "ratings_df = pl.read_csv(\"../data/ratings.csv\", schema={\"userId\": pl.Int32, \"movieId\": pl.Int32, \"rating\": pl.Float32, \"timestamp\": pl.Int32})\n",
    "tags_df = pl.read_csv(\"../data/tags.csv\", schema={\"userId\": pl.Int32, \"movieId\": pl.Int32, \"tag\": pl.String, \"timestamp\": pl.Int32})\n",
    "\n",
    "print(\"Number of ratings: \", ratings_df.height)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ratings:  100836\n"
     ]
    }
   ],
   "execution_count": 156
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T16:11:00.846015Z",
     "start_time": "2024-11-07T16:11:00.838076Z"
    }
   },
   "source": [
    "print(links_df)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (9_742, 3)\n",
      "┌─────────┬─────────┬────────┐\n",
      "│ movieId ┆ imdb    ┆ tmdbId │\n",
      "│ ---     ┆ ---     ┆ ---    │\n",
      "│ i32     ┆ i32     ┆ i32    │\n",
      "╞═════════╪═════════╪════════╡\n",
      "│ 1       ┆ 114709  ┆ 862    │\n",
      "│ 2       ┆ 113497  ┆ 8844   │\n",
      "│ 3       ┆ 113228  ┆ 15602  │\n",
      "│ 4       ┆ 114885  ┆ 31357  │\n",
      "│ 5       ┆ 113041  ┆ 11862  │\n",
      "│ …       ┆ …       ┆ …      │\n",
      "│ 193581  ┆ 5476944 ┆ 432131 │\n",
      "│ 193583  ┆ 5914996 ┆ 445030 │\n",
      "│ 193585  ┆ 6397426 ┆ 479308 │\n",
      "│ 193587  ┆ 8391976 ┆ 483455 │\n",
      "│ 193609  ┆ 101726  ┆ 37891  │\n",
      "└─────────┴─────────┴────────┘\n"
     ]
    }
   ],
   "execution_count": 157
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T16:11:00.863214Z",
     "start_time": "2024-11-07T16:11:00.847603Z"
    }
   },
   "source": [
    "print(movies_df)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (9_742, 4)\n",
      "┌───────┬─────────┬─────────────────────────────────┬─────────────────────────────────┐\n",
      "│ index ┆ movieId ┆ title                           ┆ genres                          │\n",
      "│ ---   ┆ ---     ┆ ---                             ┆ ---                             │\n",
      "│ i32   ┆ i32     ┆ str                             ┆ str                             │\n",
      "╞═══════╪═════════╪═════════════════════════════════╪═════════════════════════════════╡\n",
      "│ 0     ┆ 1       ┆ Toy Story (1995)                ┆ Adventure|Animation|Children|C… │\n",
      "│ 1     ┆ 2       ┆ Jumanji (1995)                  ┆ Adventure|Children|Fantasy      │\n",
      "│ 2     ┆ 3       ┆ Grumpier Old Men (1995)         ┆ Comedy|Romance                  │\n",
      "│ 3     ┆ 4       ┆ Waiting to Exhale (1995)        ┆ Comedy|Drama|Romance            │\n",
      "│ 4     ┆ 5       ┆ Father of the Bride Part II (1… ┆ Comedy                          │\n",
      "│ …     ┆ …       ┆ …                               ┆ …                               │\n",
      "│ 9737  ┆ 193581  ┆ Black Butler: Book of the Atla… ┆ Action|Animation|Comedy|Fantas… │\n",
      "│ 9738  ┆ 193583  ┆ No Game No Life: Zero (2017)    ┆ Animation|Comedy|Fantasy        │\n",
      "│ 9739  ┆ 193585  ┆ Flint (2017)                    ┆ Drama                           │\n",
      "│ 9740  ┆ 193587  ┆ Bungo Stray Dogs: Dead Apple (… ┆ Action|Animation                │\n",
      "│ 9741  ┆ 193609  ┆ Andrew Dice Clay: Dice Rules (… ┆ Comedy                          │\n",
      "└───────┴─────────┴─────────────────────────────────┴─────────────────────────────────┘\n"
     ]
    }
   ],
   "execution_count": 158
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T16:11:00.880212Z",
     "start_time": "2024-11-07T16:11:00.864597Z"
    }
   },
   "source": [
    "print(ratings_df)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (100_836, 4)\n",
      "┌────────┬─────────┬────────┬────────────┐\n",
      "│ userId ┆ movieId ┆ rating ┆ timestamp  │\n",
      "│ ---    ┆ ---     ┆ ---    ┆ ---        │\n",
      "│ i32    ┆ i32     ┆ f32    ┆ i32        │\n",
      "╞════════╪═════════╪════════╪════════════╡\n",
      "│ 1      ┆ 1       ┆ 4.0    ┆ 964982703  │\n",
      "│ 1      ┆ 3       ┆ 4.0    ┆ 964981247  │\n",
      "│ 1      ┆ 6       ┆ 4.0    ┆ 964982224  │\n",
      "│ 1      ┆ 47      ┆ 5.0    ┆ 964983815  │\n",
      "│ 1      ┆ 50      ┆ 5.0    ┆ 964982931  │\n",
      "│ …      ┆ …       ┆ …      ┆ …          │\n",
      "│ 610    ┆ 166534  ┆ 4.0    ┆ 1493848402 │\n",
      "│ 610    ┆ 168248  ┆ 5.0    ┆ 1493850091 │\n",
      "│ 610    ┆ 168250  ┆ 5.0    ┆ 1494273047 │\n",
      "│ 610    ┆ 168252  ┆ 5.0    ┆ 1493846352 │\n",
      "│ 610    ┆ 170875  ┆ 3.0    ┆ 1493846415 │\n",
      "└────────┴─────────┴────────┴────────────┘\n"
     ]
    }
   ],
   "execution_count": 159
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T16:11:00.895300Z",
     "start_time": "2024-11-07T16:11:00.882731Z"
    }
   },
   "source": [
    "print(tags_df)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (3_683, 4)\n",
      "┌────────┬─────────┬──────────────────┬────────────┐\n",
      "│ userId ┆ movieId ┆ tag              ┆ timestamp  │\n",
      "│ ---    ┆ ---     ┆ ---              ┆ ---        │\n",
      "│ i32    ┆ i32     ┆ str              ┆ i32        │\n",
      "╞════════╪═════════╪══════════════════╪════════════╡\n",
      "│ 2      ┆ 60756   ┆ funny            ┆ 1445714994 │\n",
      "│ 2      ┆ 60756   ┆ Highly quotable  ┆ 1445714996 │\n",
      "│ 2      ┆ 60756   ┆ will ferrell     ┆ 1445714992 │\n",
      "│ 2      ┆ 89774   ┆ Boxing story     ┆ 1445715207 │\n",
      "│ 2      ┆ 89774   ┆ MMA              ┆ 1445715200 │\n",
      "│ …      ┆ …       ┆ …                ┆ …          │\n",
      "│ 606    ┆ 7382    ┆ for katie        ┆ 1171234019 │\n",
      "│ 606    ┆ 7936    ┆ austere          ┆ 1173392334 │\n",
      "│ 610    ┆ 3265    ┆ gun fu           ┆ 1493843984 │\n",
      "│ 610    ┆ 3265    ┆ heroic bloodshed ┆ 1493843978 │\n",
      "│ 610    ┆ 168248  ┆ Heroic Bloodshed ┆ 1493844270 │\n",
      "└────────┴─────────┴──────────────────┴────────────┘\n"
     ]
    }
   ],
   "execution_count": 160
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b)\n",
    "User-based collaborative filtering using the Pearson correlation function.\n",
    "\n",
    "The pearson correlation function is found in polars so there is no need to implement it from scratch. The funciton will take into account only the ratings that are rated by both users. This is done by filtering out the ratings that are not rated by both users ignoring nan values.\n",
    "\n",
    "Let's calculate top similar users for userId 1 using Pearson correlation\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T16:18:51.670831Z",
     "start_time": "2024-11-07T16:18:51.606815Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_top_n_most_similar_users(user_id, n):\n",
    "    correlation_df = (\n",
    "        ratings_df\n",
    "        .drop(\"timestamp\")\n",
    "        .pivot(\"userId\", index=\"movieId\")\n",
    "        .drop(\"movieId\")\n",
    "        .select(pl.corr(pl.all(), str(user_id), method=\"pearson\"))\n",
    "        .transpose(include_header=True, header_name=\"userId\", column_names=[\"correlation\"])\n",
    "        .cast({\"userId\": pl.Int16})\n",
    "        .filter(pl.col(\"correlation\").is_not_nan()) # filter out NaN values\n",
    "        .sort([\"correlation\", \"userId\"], descending=[True, False])\n",
    "        .filter(pl.col(\"userId\") != user_id) # filter out the user itself\n",
    "        .filter(pl.col(\"correlation\") > 0.2) # filter out users with low correlation\n",
    "        .limit(n)\n",
    "    )\n",
    "    return (\n",
    "        correlation_df\n",
    "        .select(\"userId\")\n",
    "        .to_numpy()\n",
    "        .reshape(-1)\n",
    "    ), (\n",
    "        correlation_df\n",
    "        .select(\"correlation\")\n",
    "        .to_numpy()\n",
    "        .reshape(-1)\n",
    "    )\n",
    "\n",
    "# Calculate the top 50 most similar users to userId 1\n",
    "user_ids, similarity_scores = get_top_n_most_similar_users(1, 50)\n",
    "print(user_ids)\n",
    "print(similarity_scores)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[106 146 333 550 598 473 511   9  13 366 401 535 154 481  90 499 157 139\n",
      " 476 487 210 114 530  49 162 297 207  44 430 394 574 421 248 173  65 505\n",
      " 369 435 375 431 351  72 206 120 344 112  99 445 494 467]\n",
      "[1.         1.         1.         1.         1.         0.9622505\n",
      " 0.9258201  0.91855866 0.8783101  0.8728716  0.8669214  0.86640024\n",
      " 0.8660254  0.8660254  0.8215838  0.8029551  0.80178374 0.7905694\n",
      " 0.78693587 0.7745967  0.7676495  0.7592566  0.75592893 0.75\n",
      " 0.7083333  0.7062815  0.7016464  0.6844476  0.65465367 0.6506001\n",
      " 0.6437963  0.64122343 0.62469506 0.6172134  0.61237246 0.61237246\n",
      " 0.61209774 0.6109598  0.6061281  0.6030227  0.6        0.5964321\n",
      " 0.5962848  0.59487444 0.58760905 0.58389246 0.58345    0.56906945\n",
      " 0.5673498  0.5669467 ]\n"
     ]
    }
   ],
   "execution_count": 161
  },
  {
   "cell_type": "markdown",
   "source": [
    "Pearson correlation function has two major problems. If the standard deviation of either of the ratings is 0 the function will give nan result as there is a division by zero. This is a problem since in a case where the user has given same score for all movies the standard deviation will be 0 and the function will not work. For example users with ratings [5, 5, 5, 5] and [5, 5, 5, 5] will have a correlation of nan even though they are exactly similar. Also users with low and high ratings e.g. [5, 4, 5, 5] and [2, 1, 2, 2] will still have high Pearson correlation even though they are not similar at all."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (1, 1)\n",
      "┌─────┐\n",
      "│ a   │\n",
      "│ --- │\n",
      "│ f64 │\n",
      "╞═════╡\n",
      "│ NaN │\n",
      "└─────┘\n",
      "shape: (1, 1)\n",
      "┌─────┐\n",
      "│ c   │\n",
      "│ --- │\n",
      "│ f64 │\n",
      "╞═════╡\n",
      "│ 1.0 │\n",
      "└─────┘\n"
     ]
    }
   ],
   "source": [
    "# Example of the problems with Pearson correlation\n",
    "df = pl.DataFrame(\n",
    "    {\n",
    "    \"a\": [5, 5, 5, 5],\n",
    "    \"b\": [5, 5, 5, 5],\n",
    "    \"c\": [5, 4, 5, 5],\n",
    "    \"d\": [2, 1, 2, 2],\n",
    "    }\n",
    ")\n",
    "\n",
    "print(df.select(pl.corr(\"a\", \"b\", method=\"pearson\")))\n",
    "print(df.select(pl.corr(\"c\", \"d\", method=\"pearson\")))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### c)\n",
    "Prediction function from course slides"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def predict_movies(user_ratings_mean, similar_users_ratings, similar_users_ratings_mean, similarity_scores, candidate_movie_indices, num_of_movies):\n",
    "    \"\"\"\n",
    "    The prediction function from course slides.\n",
    "\n",
    "    :param user_ratings_mean: mean of user ratings\n",
    "    :param similar_users_ratings: sparse numpy 2D matrix of similar users ratings. Each row is a user and each column is a movie\n",
    "    :param similar_users_ratings_mean: numpy array of mean ratings of the similar users\n",
    "    :param similarity_scores: numpy array of similarity scores between the user and the similar users\n",
    "    :param candidate_movie_indices: numpy array of movie indices that the similar users have rated\n",
    "    :param num_of_movies: number of movies to recommend\n",
    "    :return: top ranked candidate movie indices, and their predicted ratings\n",
    "    \"\"\"\n",
    "    \n",
    "    # Compute ratings only for the candidate movies to save computation\n",
    "    candidate_similar_users_ratings = np.take(similar_users_ratings, candidate_movie_indices, axis=1)\n",
    "\n",
    "    # Subtract mean rating from each rating, (r_b,p - r_b)\n",
    "    delta_ratings = candidate_similar_users_ratings - similar_users_ratings_mean.reshape(similar_users_ratings_mean.shape[0], 1)\n",
    "\n",
    "    # Sum sim(a,b) * (r_b,p - r_b)\n",
    "    numerator = np.sum(similarity_scores.reshape(-1, 1) * delta_ratings, axis=0)\n",
    "\n",
    "    # Sum |sim(a,b)|, taking absolute value to avoid negative bias even though it should not be possible\n",
    "    denominator = np.sum(np.abs(similarity_scores))\n",
    "\n",
    "    # Sum sim(a,b) * (r_b,p - r_b) / Sum |sim(a,b)|\n",
    "    bias = numerator / denominator\n",
    "\n",
    "    # pred(a,p) = r_a + bias\n",
    "    predicted_ratings = user_ratings_mean + bias\n",
    "\n",
    "    # Rank the movies by predicted rating\n",
    "    indices = np.flip(np.argsort(predicted_ratings))\n",
    "    predicted_movie_indices = candidate_movie_indices[indices][:num_of_movies]\n",
    "    sorted_ratings = predicted_ratings[indices][:num_of_movies]\n",
    "\n",
    "    return predicted_movie_indices, sorted_ratings"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-07T17:33:37.088690Z",
     "start_time": "2024-11-07T17:33:37.083664Z"
    }
   },
   "outputs": [],
   "execution_count": 163
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's predict movies for userId 1 using the top 50 most similar users and the prediction function from the course slides"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4. nan  4. ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [ 4. nan nan ... nan nan nan]]\n",
      "[4.3663793 3.9482758 2.4358974 3.5555556 3.6363637]\n",
      "[ 0  1  2 88 99]\n",
      "[ 437  210 1302 4641  485  991 2019 1263  312  171]\n"
     ]
    }
   ],
   "source": [
    "# Define some helper functions to extract data from the dataframes\n",
    "\n",
    "# ratings\n",
    "def get_ratings_for_users(user_ids):\n",
    "    return (\n",
    "        ratings_df\n",
    "        .drop(\"timestamp\")\n",
    "        .sort(\"movieId\")\n",
    "        .pivot(\"userId\", index=\"movieId\")\n",
    "        .drop(\"movieId\")\n",
    "        .select([str(user_id) for user_id in user_ids])\n",
    "        .transpose(include_header=True, header_name=\"userId\", column_names=user_ids)\n",
    "        .drop(\"userId\")\n",
    "        .to_numpy()\n",
    "    )\n",
    "user_ids = np.array([1, 2, 3, 4, 5])\n",
    "print(get_ratings_for_users(user_ids))\n",
    "\n",
    "# ratings mean\n",
    "def get_mean_ratings_for_users(user_ids):\n",
    "    return (\n",
    "        ratings_df\n",
    "        .drop(\"timestamp\")\n",
    "        .sort(\"movieId\")\n",
    "        .pivot(\"userId\", index=\"movieId\")\n",
    "        .drop(\"movieId\")\n",
    "        .select([str(user_id) for user_id in user_ids.tolist()])\n",
    "        .select(pl.all().mean())\n",
    "        .transpose(include_header=True, header_name=\"userId\", column_names=[\"ratings_mean\"])\n",
    "        .cast({\"userId\": pl.Int16})\n",
    "        .filter(pl.col(\"userId\").is_in(user_ids))\n",
    "        .select(\"ratings_mean\")\n",
    "        .to_numpy()\n",
    "        .reshape(-1)\n",
    "    )\n",
    "print(get_mean_ratings_for_users(user_ids))\n",
    "\n",
    "# movie indices for movie ids\n",
    "def get_movie_indices_for_movie_ids(movie_ids):\n",
    "    return (\n",
    "        movies_df\n",
    "        .filter(pl.col(\"movieId\").is_in(movie_ids))\n",
    "        .select(\"index\")\n",
    "        .to_numpy()\n",
    "        .reshape(-1)\n",
    "    )\n",
    "print(get_movie_indices_for_movie_ids(np.array([1, 2, 3, 100, 112])))\n",
    "\n",
    "# single user rating mean\n",
    "def get_user_rating_mean(user_id):\n",
    "    return get_mean_ratings_for_users(np.array([user_id]))[0]\n",
    "\n",
    "# candidate movie ids\n",
    "def get_candidate_movie_ids(user_id, similar_user_ids):\n",
    "    rated_by_user = (\n",
    "        ratings_df\n",
    "        .filter(pl.col(\"userId\") == user_id)\n",
    "        .select(\"movieId\")\n",
    "        .to_numpy()\n",
    "        .reshape(-1)\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        ratings_df\n",
    "        .filter(\n",
    "            pl.col(\"userId\").is_in(similar_user_ids), # only include ratings from similar users\n",
    "            pl.col(\"movieId\").is_in(rated_by_user).not_() # only include movies that the user has not rated\n",
    "        )\n",
    "        .group_by(\"movieId\")\n",
    "        .agg()\n",
    "        .select(\"movieId\")\n",
    "        .to_numpy()\n",
    "        .reshape(-1)\n",
    "    )\n",
    "\n",
    "print(get_candidate_movie_ids(1, np.array([2, 3, 4, 5, 6]))[:10])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now predict 10 movies for userId 1 using the top 50 most similar users"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Recommend 10 movies for userId 1\n",
    "user_id = 1\n",
    "\n",
    "user_ratings_mean = get_user_rating_mean(user_id)\n",
    "top_50_most_similar_user_ids, similarity_scores = get_top_n_most_similar_users(1, 50)\n",
    "similar_users_ratings = np.nan_to_num(get_ratings_for_users(top_50_most_similar_user_ids))\n",
    "similar_users_ratings_mean = get_mean_ratings_for_users(top_50_most_similar_user_ids)\n",
    "candidate_movie_ids = get_candidate_movie_ids(user_id, top_50_most_similar_user_ids)\n",
    "candidate_movie_indices = get_movie_indices_for_movie_ids(candidate_movie_ids)\n",
    "\n",
    "predicted_movie_indices, ratings = predict_movies(user_ratings_mean, similar_users_ratings, similar_users_ratings_mean, similarity_scores, candidate_movie_indices, 10)\n",
    "\n",
    "print('predicted movie indices:')\n",
    "print(predicted_movie_indices)\n",
    "print()\n",
    "print('predicted ratings:')\n",
    "print(ratings)\n",
    "print()\n",
    "\n",
    "top_10_ratings_df = (\n",
    "    pl.DataFrame({\"index\": predicted_movie_indices,\n",
    "                  \"predicted_rating\": ratings})\n",
    ")\n",
    "\n",
    "# print top 10 movies\n",
    "top_10_movies_df = (\n",
    "    movies_df\n",
    "    .filter(pl.col(\"index\").is_in(predicted_movie_indices))\n",
    "    .join(top_10_ratings_df, on=\"index\")\n",
    "    .drop(\"index\")\n",
    ")\n",
    "\n",
    "print(top_10_movies_df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-07T17:36:38.983765Z",
     "start_time": "2024-11-07T17:36:38.704036Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted movie indices:\n",
      "[ 277 1938 7355  123   31  507 2144  302  126  506]\n",
      "\n",
      "predicted ratings:\n",
      "[2.3414884 2.2917266 1.8985755 1.4971073 1.4671545 1.2913637 1.2901106\n",
      " 1.2001786 1.1979115 1.1787481]\n",
      "\n",
      "shape: (10, 4)\n",
      "┌─────────┬─────────────────────────────────┬─────────────────────────────────┬──────────────────┐\n",
      "│ movieId ┆ title                           ┆ genres                          ┆ predicted_rating │\n",
      "│ ---     ┆ ---                             ┆ ---                             ┆ ---              │\n",
      "│ i32     ┆ str                             ┆ str                             ┆ f32              │\n",
      "╞═════════╪═════════════════════════════════╪═════════════════════════════════╪══════════════════╡\n",
      "│ 318     ┆ Shawshank Redemption, The (199… ┆ Crime|Drama                     ┆ 2.341488         │\n",
      "│ 2570    ┆ Walk on the Moon, A (1999)      ┆ Drama|Romance                   ┆ 2.291727         │\n",
      "│ 78499   ┆ Toy Story 3 (2010)              ┆ Adventure|Animation|Children|C… ┆ 1.898576         │\n",
      "│ 150     ┆ Apollo 13 (1995)                ┆ Adventure|Drama|IMAX            ┆ 1.497107         │\n",
      "│ 32      ┆ Twelve Monkeys (a.k.a. 12 Monk… ┆ Mystery|Sci-Fi|Thriller         ┆ 1.467155         │\n",
      "│ 589     ┆ Terminator 2: Judgment Day (19… ┆ Action|Sci-Fi                   ┆ 1.291364         │\n",
      "│ 2857    ┆ Yellow Submarine (1968)         ┆ Adventure|Animation|Comedy|Fan… ┆ 1.290111         │\n",
      "│ 344     ┆ Ace Ventura: Pet Detective (19… ┆ Comedy                          ┆ 1.200179         │\n",
      "│ 153     ┆ Batman Forever (1995)           ┆ Action|Adventure|Comedy|Crime   ┆ 1.197912         │\n",
      "│ 588     ┆ Aladdin (1992)                  ┆ Adventure|Animation|Children|C… ┆ 1.178748         │\n",
      "└─────────┴─────────────────────────────────┴─────────────────────────────────┴──────────────────┘\n"
     ]
    }
   ],
   "execution_count": 190
  },
  {
   "cell_type": "markdown",
   "source": [
    "From the results we can see that the Pearson correlation function did not work quite well on itself. The best predicted rating is only 2.34 which is considered a bad rating."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### d)\n",
    "\n",
    "New similarity function\n",
    "\n",
    "We chose the cosine similarity as a distance measure for the following reasons:\n",
    "    - It is a common similarity measure for collaborative filtering\n",
    "    - It is a good distance measure for sparse data\n",
    "\n",
    "However, since the cosine similarity does not depend on magnitude of the vector it means that with our rating scale 1-5 the ratings of three movies [1, 1, 1] and [5, 5, 5] would be treated as eaqual in the cosine similarity calculation. This is of course false so we cannot use the plain cosine similarity measure for our application. What we do is to split the ratings into two groups, positive and negative ratings. We then calculate the cosine similarity for each group and combine them with a weighted average. We give more weight to the positive ratings since they are more important for the recommendation system.\n",
    "\n",
    "We apply the same method of masking b to only include ratings that are rated by a in order to have a fair comparison.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "def get_cosine_similarity(a, b):\n",
    "\n",
    "    a_positive = np.copy(a)\n",
    "    b_positive = np.copy(b)\n",
    "\n",
    "    # mask out all ratings of user b which are not rated by user a\n",
    "    mask = a_positive == 0\n",
    "    b_positive[mask] = 0\n",
    "\n",
    "    a_negative = np.copy(a_positive)\n",
    "    b_negative = np.copy(b_positive)\n",
    "\n",
    "    pos_threshold = 2.5\n",
    "    # positive ratings cosine similarity\n",
    "    a_positive[a_positive <= pos_threshold] = 0\n",
    "    b_positive[b_positive <= pos_threshold] = 0\n",
    "\n",
    "    positive_similarity = 0\n",
    "    if np.sum(a_positive) != 0 and np.sum(b_positive) != 0:\n",
    "        positive_similarity = 1 - distance.cosine(a_positive, b_positive)\n",
    "\n",
    "    # negative ratings cosine similarity\n",
    "    a_negative[a_negative > pos_threshold] = 0\n",
    "    b_negative[b_negative > pos_threshold] = 0\n",
    "\n",
    "    negative_similarity = 0\n",
    "    if np.sum(a_negative) != 0 and np.sum(b_negative) != 0:\n",
    "        negative_similarity = 1 - distance.cosine(a_negative, b_negative)\n",
    "\n",
    "    # combine positive and negative similarity. Give more weight to positive similarity\n",
    "    w_pos = 1.5\n",
    "    w_neg = 1\n",
    "    return (w_pos * positive_similarity + w_neg * negative_similarity) / (w_pos + w_neg)\n",
    "\n",
    "# Test\n",
    "a = np.array([4, 4, 0, 4, ])\n",
    "b = np.array([5, 0, 3, 5])\n",
    "c = np.array([1, 1, 1, 0])\n",
    "d = np.array([3, 2, 3, 2])\n",
    "\n",
    "cosine_similarity = lambda a, b: get_cosine_similarity(a, b)\n",
    "\n",
    "print(cosine_similarity(a, b))\n",
    "print(cosine_similarity(a, c))\n",
    "print(cosine_similarity(a, d))\n",
    "print(cosine_similarity(c, d))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-07T17:37:23.554622Z",
     "start_time": "2024-11-07T17:37:14.339818Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4898979485566356\n",
      "0.0\n",
      "0.34641016151377546\n",
      "0.23094010767585033\n"
     ]
    }
   ],
   "execution_count": 167
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### e)\n",
    "User-based collaborative filtering for group recommendations."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Create a group of users by picking the first 5 userIds\n",
    "user_ids = [1, 2, 3, 4, 5]\n",
    "# group = ratings_df.filter(pl.col(\"userId\").is_in(userIds))\n",
    "# print('Group:')\n",
    "# print(group)\n",
    "# print()\n",
    "\n",
    "\n",
    "# Combine all the above functions to predict movies for a single user\n",
    "def predict_movies_for_user(user_id, num_of_movies):\n",
    "    similar_user_ids, similarity_scores = get_top_n_most_similar_users(user_id, 50)\n",
    "    print(similarity_scores)\n",
    "\n",
    "    user_ratings_mean = get_user_rating_mean(user_id)\n",
    "    similar_users_ratings = np.nan_to_num(get_ratings_for_users(similar_user_ids))\n",
    "    similar_users_ratings_mean = get_mean_ratings_for_users(similar_user_ids)\n",
    "    candidate_movie_ids = get_candidate_movie_ids(user_id, similar_user_ids)\n",
    "    candidate_movie_indices = get_movie_indices_for_movie_ids(candidate_movie_ids)\n",
    "\n",
    "    return predict_movies(user_ratings_mean, similar_users_ratings, similar_users_ratings_mean, similarity_scores, candidate_movie_indices, num_of_movies)\n",
    "\n",
    "\n",
    "n_movies = 500\n",
    "predicted_movie_indices = np.ndarray(shape=(len(user_ids), n_movies), dtype=np.int32)\n",
    "predicted_ratings = np.ndarray(shape=(len(user_ids), n_movies), dtype=np.float32)\n",
    "\n",
    "for index, user_id in enumerate(user_ids):\n",
    "    user_movie_indices, ratings = predict_movies_for_user(user_id, n_movies)\n",
    "    predicted_movie_indices[index] = user_movie_indices\n",
    "    predicted_ratings[index] = ratings\n",
    "\n",
    "# Print top 10 movies for each user\n",
    "print('Predicted movie indices:')\n",
    "print(predicted_movie_indices[:, :10])\n",
    "print()\n",
    "print('Predicted ratings:')\n",
    "print(predicted_ratings[:, :10])\n",
    "print()\n",
    "\n",
    "\n",
    "# Combine the predictions into a dataframe\n",
    "predictions_df = (\n",
    "    pl.DataFrame({\"movie_index\": predicted_movie_indices.reshape(-1),\n",
    "                  \"predicted_rating\": predicted_ratings.reshape(-1),\n",
    "                  \"userId\": np.array([[userId] * n_movies for userId in userIds]).reshape(-1)})\n",
    "    .unique()\n",
    "    )\n",
    "\n",
    "# Find movies which have rating for all users in the group\n",
    "movie_ratings_count = (\n",
    "    predictions_df\n",
    "    .group_by(\"movie_index\")\n",
    "    .agg(\n",
    "        pl.count(\"predicted_rating\")\n",
    "        .alias(\"ratings_count\")\n",
    "    )\n",
    "    .filter(pl.col(\"ratings_count\") >= 5)\n",
    "    .sort(\"ratings_count\", descending=True)\n",
    ")\n",
    "\n",
    "# filter predictions_df to only include movies that have been rated by all users in the group\n",
    "predictions_df = (\n",
    "    predictions_df\n",
    "    .filter(\n",
    "        pl.col(\"movie_index\")\n",
    "        .is_in(movie_ratings_count.select(\"movie_index\")\n",
    "               )\n",
    "    )\n",
    "    .sort(\"movie_index\")\n",
    "    .pivot(\"movie_index\", index=\"userId\")\n",
    ")\n",
    "print(predictions_df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-07T17:55:48.067028Z",
     "start_time": "2024-11-07T17:55:47.772134Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         1.         1.         1.         1.         0.9622505\n",
      " 0.9258201  0.91855866 0.8783101  0.8728716  0.8669214  0.86640024\n",
      " 0.8660254  0.8660254  0.8215838  0.8029551  0.80178374 0.7905694\n",
      " 0.78693587 0.7745967  0.7676495  0.7592566  0.75592893 0.75\n",
      " 0.7083333  0.7062815  0.7016464  0.6844476  0.65465367 0.6506001\n",
      " 0.6437963  0.64122343 0.62469506 0.6172134  0.61237246 0.61237246\n",
      " 0.61209774 0.6109598  0.6061281  0.6030227  0.6        0.5964321\n",
      " 0.5962848  0.59487444 0.58760905 0.58389246 0.58345    0.56906945\n",
      " 0.5673498  0.5669467 ]\n",
      "[1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         0.9449112  0.8660254  0.8660254  0.80757284 0.7894737\n",
      " 0.70636564 0.69337523 0.6875     0.6621222  0.6232876  0.5833333\n",
      " 0.5833333  0.57735026 0.572822   0.56642324 0.54395807 0.53033006\n",
      " 0.50536954 0.5037349  0.5        0.5        0.49408695 0.49407724\n",
      " 0.46513027 0.4397966  0.4128614  0.39718696 0.3859225  0.378681\n",
      " 0.37015015 0.34585723 0.3380617  0.33184075 0.32444283 0.3044612\n",
      " 0.28097573 0.260133  ]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 9731 is out of bounds for axis 1 with size 9724",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[168], line 28\u001B[0m\n\u001B[0;32m     25\u001B[0m predicted_ratings \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mndarray(shape\u001B[38;5;241m=\u001B[39m(\u001B[38;5;28mlen\u001B[39m(user_ids), n_movies), dtype\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39mfloat32)\n\u001B[0;32m     27\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m index, user_id \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(user_ids):\n\u001B[1;32m---> 28\u001B[0m     user_movie_indices, ratings \u001B[38;5;241m=\u001B[39m \u001B[43mpredict_movies_for_user\u001B[49m\u001B[43m(\u001B[49m\u001B[43muser_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_movies\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     29\u001B[0m     predicted_movie_indices[index] \u001B[38;5;241m=\u001B[39m user_movie_indices\n\u001B[0;32m     30\u001B[0m     predicted_ratings[index] \u001B[38;5;241m=\u001B[39m ratings\n",
      "Cell \u001B[1;32mIn[168], line 20\u001B[0m, in \u001B[0;36mpredict_movies_for_user\u001B[1;34m(user_id, num_of_movies)\u001B[0m\n\u001B[0;32m     17\u001B[0m candidate_movie_ids \u001B[38;5;241m=\u001B[39m get_candidate_movie_ids(user_id, similar_user_ids)\n\u001B[0;32m     18\u001B[0m candidate_movie_indices \u001B[38;5;241m=\u001B[39m get_movie_indices_for_movie_ids(candidate_movie_ids)\n\u001B[1;32m---> 20\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mpredict_movies\u001B[49m\u001B[43m(\u001B[49m\u001B[43muser_ratings_mean\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msimilar_users_ratings\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msimilar_users_ratings_mean\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msimilarity_scores\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcandidate_movie_indices\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_of_movies\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[163], line 15\u001B[0m, in \u001B[0;36mpredict_movies\u001B[1;34m(user_ratings_mean, similar_users_ratings, similar_users_ratings_mean, similarity_scores, candidate_movie_indices, num_of_movies)\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;124;03mThe prediction function from course slides.\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;124;03m:return: top ranked candidate movie indices, and their predicted ratings\u001B[39;00m\n\u001B[0;32m     12\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     14\u001B[0m \u001B[38;5;66;03m# Compute ratings only for the candidate movies to save computation\u001B[39;00m\n\u001B[1;32m---> 15\u001B[0m candidate_similar_users_ratings \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtake\u001B[49m\u001B[43m(\u001B[49m\u001B[43msimilar_users_ratings\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcandidate_movie_indices\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;66;03m# Subtract mean rating from each rating, (r_b,p - r_b)\u001B[39;00m\n\u001B[0;32m     18\u001B[0m delta_ratings \u001B[38;5;241m=\u001B[39m candidate_similar_users_ratings \u001B[38;5;241m-\u001B[39m similar_users_ratings_mean\u001B[38;5;241m.\u001B[39mreshape(similar_users_ratings_mean\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[1;32m~\\.virtualenvs\\DATA.ML.360-Recommender-Systems-HXMQeDrO\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:207\u001B[0m, in \u001B[0;36mtake\u001B[1;34m(a, indices, axis, out, mode)\u001B[0m\n\u001B[0;32m    109\u001B[0m \u001B[38;5;129m@array_function_dispatch\u001B[39m(_take_dispatcher)\n\u001B[0;32m    110\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtake\u001B[39m(a, indices, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, out\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mraise\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[0;32m    111\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    112\u001B[0m \u001B[38;5;124;03m    Take elements from an array along an axis.\u001B[39;00m\n\u001B[0;32m    113\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    205\u001B[0m \u001B[38;5;124;03m           [5, 7]])\u001B[39;00m\n\u001B[0;32m    206\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 207\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_wrapfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtake\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindices\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.virtualenvs\\DATA.ML.360-Recommender-Systems-HXMQeDrO\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:57\u001B[0m, in \u001B[0;36m_wrapfunc\u001B[1;34m(obj, method, *args, **kwds)\u001B[0m\n\u001B[0;32m     54\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _wrapit(obj, method, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m     56\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 57\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mbound\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     58\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[0;32m     59\u001B[0m     \u001B[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001B[39;00m\n\u001B[0;32m     60\u001B[0m     \u001B[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     64\u001B[0m     \u001B[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001B[39;00m\n\u001B[0;32m     65\u001B[0m     \u001B[38;5;66;03m# exception has a traceback chain.\u001B[39;00m\n\u001B[0;32m     66\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _wrapit(obj, method, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n",
      "\u001B[1;31mIndexError\u001B[0m: index 9731 is out of bounds for axis 1 with size 9724"
     ]
    }
   ],
   "execution_count": 168
  },
  {
   "cell_type": "markdown",
   "source": [
    "Average aggregated recommendations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Calculate the average rating for each movie\n",
    "average_ratings_df = (\n",
    "    predictions_df\n",
    "    .drop(\"userId\")\n",
    "    .mean()\n",
    ")\n",
    "\n",
    "print(\"Average ratings:\")\n",
    "print(average_ratings_df)\n",
    "print()\n",
    "\n",
    "# find the top 10 movies based on the average rating\n",
    "top_10_movies_avg_df = (\n",
    "    average_ratings_df\n",
    "    .transpose(include_header=True, header_name=\"index\", column_names=[\"avg_rating\"])\n",
    "    .with_columns(\n",
    "        pl.col(\"index\")\n",
    "        .cast(pl.Int32)\n",
    "    )\n",
    "    .sort(\"avg_rating\", descending=True)\n",
    "    .limit(10)\n",
    "    .join(movies_df, on=\"index\", how=\"left\")\n",
    ")\n",
    "\n",
    "print(\"Top 10 movies:\")\n",
    "print(top_10_movies_avg_df)\n",
    "print()"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Least misery aggregated recommendations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Calculate least misery rating for each movie\n",
    "least_misery_ratings_df = (\n",
    "    predictions_df\n",
    "    .drop(\"userId\")\n",
    "    .min()\n",
    ")\n",
    "\n",
    "print(\"Least misery ratings:\")\n",
    "print(least_misery_ratings_df)\n",
    "print()\n",
    "\n",
    "# find the top 10 movies based on the least misery rating\n",
    "top_10_movies_least_misery_df = (\n",
    "    least_misery_ratings_df\n",
    "    .transpose(include_header=True, header_name=\"index\", column_names=[\"least_misery_rating\"])\n",
    "    .with_columns(\n",
    "        pl.col(\"index\")\n",
    "        .cast(pl.Int32)\n",
    "    )\n",
    "    .sort(\"least_misery_rating\", descending=True)\n",
    "    .limit(10)\n",
    "    .join(movies_df, on=\"index\", how=\"left\")\n",
    ")\n",
    "\n",
    "print(\"Top 10 movies:\")\n",
    "print(top_10_movies_least_misery_df)\n",
    "print()"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Find movies that appear in both top 10 lists\n",
    "common_movies = (\n",
    "    top_10_movies_avg_df\n",
    "    .join(top_10_movies_least_misery_df, on=\"index\", how=\"inner\")\n",
    "    .select([\"index\", \"title\", \"avg_rating\", \"least_misery_rating\"])\n",
    ")\n",
    "\n",
    "print(\"Common movies:\")\n",
    "print(common_movies)\n",
    "\n",
    "# Find movies that appear in only one of the top 10 lists\n",
    "unique_movies_avg = (\n",
    "    top_10_movies_avg_df\n",
    "    .join(top_10_movies_least_misery_df, on=\"index\", how=\"anti\")\n",
    "    .select([\"index\", \"title\", \"avg_rating\"])\n",
    ")\n",
    "\n",
    "print(\"Unique movies avg:\")\n",
    "print(unique_movies_avg)\n",
    "print()\n",
    "\n",
    "unique_movies_least_misery = (\n",
    "    top_10_movies_least_misery_df\n",
    "    .join(top_10_movies_avg_df, on=\"index\", how=\"anti\")\n",
    "    .select([\"index\", \"title\", \"least_misery_rating\"])\n",
    ")\n",
    "\n",
    "print(\"Unique movies least misery:\")\n",
    "print(unique_movies_least_misery)\n",
    "print()"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "From the previous results we can see that the top 10 movies are mostly same for the average and least misery aggregation methods. Both methods have 8 movies in common and 2 unique movies. The order of the common movies varies alot. This result is expected since the two methods are based on different principles.\n",
    "\n",
    "From the predicted scores in both methods we can see that the predictions are not very good. This however, is not a fault of the measure but the group of users that we have chosen. The group of users do not seem to share a preference when it comes to movies. If we had chosen a group of users that have more similar taste, both methods would show better results.\n",
    "\n",
    "The results we have now are both a tradeoff and will now leave at least one user disliking the movie the group would watch."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### f)\n",
    "\n",
    "Disagreement between the users in a group"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
