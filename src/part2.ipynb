{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project work part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ratings:  100836\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import polars as pl\n",
    "\n",
    "# read data\n",
    "links_df = pl.read_csv(\"../data/links.csv\", schema={\"movieId\": pl.Int32, \"imdb\": pl.Int32, \"tmdbId\": pl.Int32})\n",
    "movies_df = (\n",
    "    pl.read_csv(\"../data/movies.csv\", schema={\"movieId\": pl.Int32, \"title\": pl.String, \"genres\": pl.String})\n",
    "    .with_row_index()\n",
    "    .with_columns(\n",
    "        pl.col(\"index\")\n",
    "        .cast(pl.Int32)\n",
    "    )\n",
    ")\n",
    "ratings_df = pl.read_csv(\"../data/ratings.csv\", schema={\"userId\": pl.Int32, \"movieId\": pl.Int32, \"rating\": pl.Float32, \"timestamp\": pl.Int32})\n",
    "tags_df = pl.read_csv(\"../data/tags.csv\", schema={\"userId\": pl.Int32, \"movieId\": pl.Int32, \"tag\": pl.String, \"timestamp\": pl.Int32})\n",
    "\n",
    "print(\"Number of ratings: \", ratings_df.height)\n",
    "\n",
    "# Divide the dataset to two evely sized parts based on the timestamp\n",
    "ratings_df = ratings_df.sort(\"timestamp\")\n",
    "ratings_df1 = ratings_df.slice(0, ratings_df.height // 2)\n",
    "ratings_df2 = ratings_df.slice(ratings_df.height // 2, ratings_df.height)\n",
    "\n",
    "#print(ratings_df1)\n",
    "#print(ratings_df2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 2)\n",
      "┌────────┬────────┐\n",
      "│ userId ┆ rating │\n",
      "│ ---    ┆ ---    │\n",
      "│ i64    ┆ f64    │\n",
      "╞════════╪════════╡\n",
      "│ 1      ┆ 0.0    │\n",
      "│ 2      ┆ 0.0    │\n",
      "│ 3      ┆ 0.0    │\n",
      "│ 4      ┆ 0.0    │\n",
      "│ 5      ┆ 0.0    │\n",
      "└────────┴────────┘\n"
     ]
    }
   ],
   "source": [
    "user_ids = [1, 2, 3, 4, 5]\n",
    "\n",
    "from sklearn.metrics.pairwise import nan_euclidean_distances\n",
    "\n",
    "\n",
    "def get_top_n_most_similar_users_euclidean(user_id, n):\n",
    "    rating_vectors_df = (\n",
    "        ratings_df\n",
    "        .drop(\"timestamp\")\n",
    "        .pivot(\"movieId\", index=\"userId\")\n",
    "    )\n",
    "    \n",
    "    user_ratings = rating_vectors_df.filter(pl.col(\"userId\") == user_id).drop(\"userId\").to_numpy()\n",
    "    \n",
    "    rating_vectors = (\n",
    "        rating_vectors_df\n",
    "        .drop(\"userId\")\n",
    "        .to_numpy()\n",
    "    )\n",
    "    \n",
    "    # Calculate distance\n",
    "    distances = nan_euclidean_distances(rating_vectors, user_ratings).reshape(-1)\n",
    "    \n",
    "    # Find nan values and count the amount of common movies between user and all users\n",
    "    nans_in_user_ratings = np.isnan(user_ratings[0])\n",
    "    nans_in_rating_vectors = np.isnan(rating_vectors)\n",
    "    common_rated_movies = 1 - np.logical_or(nans_in_user_ratings, nans_in_rating_vectors)\n",
    "    common_rated_movies_count = np.sum(common_rated_movies, axis=1).astype(np.float32) \n",
    "    \n",
    "    # Ignore users withe less than 5 common movies\n",
    "    common_rated_movies_count[common_rated_movies_count < 5] = np.nan \n",
    "    \n",
    "    # Count average distances\n",
    "    average_distances = distances / common_rated_movies_count\n",
    "    \n",
    "    # Max scaling\n",
    "    max_average_distance = np.nanmax(average_distances)\n",
    "    \n",
    "    # Distance to similarity. Nan values are set to zero\n",
    "    similarities = np.nan_to_num(1 - (average_distances / max_average_distance))\n",
    "    \n",
    "    distance_df = (\n",
    "        pl.DataFrame(\n",
    "            {\n",
    "                \"userId\": rating_vectors_df.select(\"userId\"),\n",
    "                \"similarity\": similarities\n",
    "            }\n",
    "        )\n",
    "        .sort(\"similarity\", descending=True)\n",
    "        .limit(n)\n",
    "    )\n",
    "    \n",
    "    return (\n",
    "        distance_df\n",
    "        .select(\"userId\")\n",
    "        .to_numpy()\n",
    "        .reshape(-1)\n",
    "    ), (\n",
    "        distance_df\n",
    "        .select(\"similarity\")\n",
    "        .to_numpy()\n",
    "        .reshape(-1)\n",
    "    )\n",
    "\n",
    "# Calculate the top 50 most similar users to userId 1\n",
    "user_ids, similarity_scores = get_top_n_most_similar_users_euclidean(1, 50)\n",
    "print(user_ids)\n",
    "print(similarity_scores)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
